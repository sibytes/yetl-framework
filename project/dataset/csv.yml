apiVersion: yetl-framework.io/1/Dataset/CSV
dataset:
  default:
    name: "{{table.name}}"
    read_options: 
      schema_versioning: true
      column_delimiter: ","
      row_delimiter: "\n"
      skip_line_count: 0
      column_names_ifr: true
      escape_character: 
      quote_character: 
      null_value: 
      empty_column_null: true
      timestamp_format: yyyy-MM-ddTHH:mm:ss.mmmZ
      date_format: yyyy-MM-dd
      encoding: utf-8
      days_retention_period: 30
      partition_path_format: YYYY/mm/dd
      partition_file_format: YYYY-mm-dd
      extension: csv
      compression_type: none
      filename: "{{datastore.name}}-{{partition_file_datetime}}.ext"
      path: "{{datastore.container}}/{{datastore.name}}/{{table.classification}}/{{datastore.schema}}/{{partition_path_datetime}}/{{version}}"
      mode: DROPMALFORMED
      columnNameOfCorruptRecord: _corrupt_record
      bad_records_path: container/datastore/exceptions/schema/partition/version
      data_schema: 
        schema_path: "{{datastore.container}}/spark_schema/{{datastore.name}}"
        spark_table_schema: "spark_{{datastore.schema}}_{{table.name}}.json"
        spark_column_schema: "spark_{{datastore.schema}}_{{table.name}}_{{table.column}}.json"
        json_table_schema: "json_{{datastore.schema}}_{{table.name}}.json"
        json_column_schema: "json_{{datastore.schema}}_{{table.name}}_{{table.column}}.json"
  permissive:
    mode: PERMISSIVE
    columnNameOfCorruptRecord: null
    bad_records_path: null